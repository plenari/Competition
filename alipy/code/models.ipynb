{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. \n",
    "    1.1 模型处理\n",
    "        1.2 获取数据\n",
    "        1.3 模型\n",
    "        1.4 多个模型\n",
    "        1.5 融合\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import jieba \n",
    "import gensim\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import lightgbm\n",
    "import sklearn\n",
    "import torch\n",
    "from torch import nn\n",
    "from sklearn.metrics import f1_score\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "doc2vec=gensim.models.Doc2Vec.load('../model/model_doc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "doc2vec.docvecs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def read2():\n",
    "    '''\n",
    "    第一次读后的结果保存之后在读取\n",
    "    '''\n",
    "    file=r'../data/nlp_train.csv'\n",
    "    train=pd.read_csv(file,sep='\\t',encoding='utf-8',header=None,index_col=None)\n",
    "    return train\n",
    "train=read2()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def read_sentences():\n",
    "    '''\n",
    "    读取分割好的句子\n",
    "    '''\n",
    "    file='../data/sentences.txt'\n",
    "    sentences=pd.read_table(file,encoding='utf-8',header=None)\n",
    "    return sentences\n",
    "sentences=read_sentences()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>﻿怎么更改花呗手机号码</td>\n",
       "      <td>我的花呗是以前的手机号码，怎么更改成现在的支付宝的号码手机号</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>也开不了花呗，就这样了？完事了</td>\n",
       "      <td>真的嘛？就是花呗付款</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>花呗冻结以后还能开通吗</td>\n",
       "      <td>我的条件可以开通花呗借款吗</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>如何得知关闭借呗</td>\n",
       "      <td>想永久关闭借呗</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>花呗扫码付钱</td>\n",
       "      <td>二维码扫描可以用花呗吗</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   0                1                               2  3\n",
       "0  1      ﻿怎么更改花呗手机号码  我的花呗是以前的手机号码，怎么更改成现在的支付宝的号码手机号  1\n",
       "1  2  也开不了花呗，就这样了？完事了                      真的嘛？就是花呗付款  0\n",
       "2  3      花呗冻结以后还能开通吗                   我的条件可以开通花呗借款吗  0\n",
       "3  4         如何得知关闭借呗                         想永久关闭借呗  0\n",
       "4  5           花呗扫码付钱                     二维码扫描可以用花呗吗  0"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>怎么 更改 花呗 手机号码</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>也 开 不了 花呗 ， 就 这样 了 ？ 完事 了</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>花呗 冻结 以后 还 能 开通 吗</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>如何 得知 关闭 借呗</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>花呗 扫码 付钱</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           0\n",
       "0              怎么 更改 花呗 手机号码\n",
       "1  也 开 不了 花呗 ， 就 这样 了 ？ 完事 了\n",
       "2          花呗 冻结 以后 还 能 开通 吗\n",
       "3                如何 得知 关闭 借呗\n",
       "4                   花呗 扫码 付钱"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentences.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def cal_train_x(sentences,model):\n",
    "    '''\n",
    "    再把分词后的句子转换成矢量\n",
    "    '''\n",
    "    train_x=[]\n",
    "    split=len(sentences)//2\n",
    "    train_x_q1=[model.infer_vector(i) for i in sentences[:split].values]\n",
    "    train_x_q2=[model.infer_vector(i) for i in sentences[-split:].values]\n",
    "    train_x=[np.concatenate((train_x_q1[i],train_x_q2[i])) for i in range(len(train_x_q1))]\n",
    "    return np.array(train_x)\n",
    "train_x=cal_train_x(sentences,doc2vec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((102477, 200), (102477, 4))"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_x.shape,train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. lightgbm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(102477,)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_y=train.loc[:,3]\n",
    "train_y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "f1_score?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LGB test\n",
      "[2000]\tvalid_0's binary_logloss: 0.536116\n",
      "[4000]\tvalid_0's binary_logloss: 0.543005\n",
      "[6000]\tvalid_0's binary_logloss: 0.551537\n",
      "[8000]\tvalid_0's binary_logloss: 0.560027\n",
      "[10000]\tvalid_0's binary_logloss: 0.570634\n",
      "[12000]\tvalid_0's binary_logloss: 0.58213\n",
      "[14000]\tvalid_0's binary_logloss: 0.594301\n",
      "[16000]\tvalid_0's binary_logloss: 0.607262\n",
      "[18000]\tvalid_0's binary_logloss: 0.620563\n",
      "[20000]\tvalid_0's binary_logloss: 0.63405\n",
      "0 0.00897263346792\n",
      "[2000]\tvalid_0's binary_logloss: 0.539035\n",
      "[4000]\tvalid_0's binary_logloss: 0.547512\n",
      "[6000]\tvalid_0's binary_logloss: 0.555521\n",
      "[8000]\tvalid_0's binary_logloss: 0.566049\n",
      "[10000]\tvalid_0's binary_logloss: 0.576777\n",
      "[12000]\tvalid_0's binary_logloss: 0.589007\n",
      "[14000]\tvalid_0's binary_logloss: 0.602032\n",
      "[16000]\tvalid_0's binary_logloss: 0.614998\n",
      "[18000]\tvalid_0's binary_logloss: 0.629537\n",
      "[20000]\tvalid_0's binary_logloss: 0.643766\n",
      "1 0.00266785237884\n",
      "[2000]\tvalid_0's binary_logloss: 0.536519\n",
      "[4000]\tvalid_0's binary_logloss: 0.544965\n",
      "[6000]\tvalid_0's binary_logloss: 0.554846\n",
      "[8000]\tvalid_0's binary_logloss: 0.565073\n",
      "[10000]\tvalid_0's binary_logloss: 0.575756\n",
      "[12000]\tvalid_0's binary_logloss: 0.588508\n",
      "[14000]\tvalid_0's binary_logloss: 0.600984\n",
      "[16000]\tvalid_0's binary_logloss: 0.615398\n",
      "[18000]\tvalid_0's binary_logloss: 0.630228\n",
      "[20000]\tvalid_0's binary_logloss: 0.644285\n",
      "2 0.0062893081761\n",
      "[2000]\tvalid_0's binary_logloss: 0.530039\n",
      "[4000]\tvalid_0's binary_logloss: 0.537746\n",
      "[6000]\tvalid_0's binary_logloss: 0.546985\n",
      "[8000]\tvalid_0's binary_logloss: 0.556266\n",
      "[10000]\tvalid_0's binary_logloss: 0.56767\n",
      "[12000]\tvalid_0's binary_logloss: 0.578439\n",
      "[14000]\tvalid_0's binary_logloss: 0.590989\n",
      "[16000]\tvalid_0's binary_logloss: 0.604596\n",
      "[18000]\tvalid_0's binary_logloss: 0.617965\n",
      "[20000]\tvalid_0's binary_logloss: 0.631805\n",
      "3 0.00639269406393\n",
      "[2000]\tvalid_0's binary_logloss: 0.450645\n",
      "[4000]\tvalid_0's binary_logloss: 0.455111\n",
      "[6000]\tvalid_0's binary_logloss: 0.459081\n",
      "[8000]\tvalid_0's binary_logloss: 0.463112\n",
      "[10000]\tvalid_0's binary_logloss: 0.467647\n",
      "[12000]\tvalid_0's binary_logloss: 0.472733\n",
      "[14000]\tvalid_0's binary_logloss: 0.478492\n",
      "[16000]\tvalid_0's binary_logloss: 0.484934\n",
      "[18000]\tvalid_0's binary_logloss: 0.492632\n",
      "[20000]\tvalid_0's binary_logloss: 0.500807\n",
      "4 0.00714285714286\n",
      "[2000]\tvalid_0's binary_logloss: 0.450393\n",
      "[4000]\tvalid_0's binary_logloss: 0.452771\n",
      "[6000]\tvalid_0's binary_logloss: 0.456175\n",
      "[8000]\tvalid_0's binary_logloss: 0.459719\n",
      "[10000]\tvalid_0's binary_logloss: 0.464694\n",
      "[12000]\tvalid_0's binary_logloss: 0.469323\n",
      "[14000]\tvalid_0's binary_logloss: 0.475195\n",
      "[16000]\tvalid_0's binary_logloss: 0.481691\n",
      "[18000]\tvalid_0's binary_logloss: 0.489456\n",
      "[20000]\tvalid_0's binary_logloss: 0.497637\n",
      "5 0.00941730429665\n",
      "[2000]\tvalid_0's binary_logloss: 0.432004\n",
      "[4000]\tvalid_0's binary_logloss: 0.434711\n",
      "[6000]\tvalid_0's binary_logloss: 0.437954\n",
      "[8000]\tvalid_0's binary_logloss: 0.441307\n",
      "[10000]\tvalid_0's binary_logloss: 0.444819\n",
      "[12000]\tvalid_0's binary_logloss: 0.448339\n",
      "[14000]\tvalid_0's binary_logloss: 0.452976\n",
      "[16000]\tvalid_0's binary_logloss: 0.458814\n",
      "[18000]\tvalid_0's binary_logloss: 0.465518\n",
      "[20000]\tvalid_0's binary_logloss: 0.471992\n",
      "6 0.0089058524173\n",
      "[2000]\tvalid_0's binary_logloss: 0.453854\n",
      "[4000]\tvalid_0's binary_logloss: 0.458118\n",
      "[6000]\tvalid_0's binary_logloss: 0.460453\n",
      "[8000]\tvalid_0's binary_logloss: 0.465574\n",
      "[10000]\tvalid_0's binary_logloss: 0.470803\n",
      "[12000]\tvalid_0's binary_logloss: 0.475998\n",
      "[14000]\tvalid_0's binary_logloss: 0.482739\n",
      "[16000]\tvalid_0's binary_logloss: 0.489581\n",
      "[18000]\tvalid_0's binary_logloss: 0.49784\n",
      "[20000]\tvalid_0's binary_logloss: 0.506082\n",
      "7 0.00583771161705\n",
      "[2000]\tvalid_0's binary_logloss: 0.460137\n",
      "[4000]\tvalid_0's binary_logloss: 0.464507\n",
      "[6000]\tvalid_0's binary_logloss: 0.469533\n",
      "[8000]\tvalid_0's binary_logloss: 0.475721\n",
      "[10000]\tvalid_0's binary_logloss: 0.48088\n",
      "[12000]\tvalid_0's binary_logloss: 0.487342\n",
      "[14000]\tvalid_0's binary_logloss: 0.493884\n",
      "[16000]\tvalid_0's binary_logloss: 0.501859\n",
      "[18000]\tvalid_0's binary_logloss: 0.510151\n",
      "[20000]\tvalid_0's binary_logloss: 0.519428\n",
      "8 0.00801373783629\n",
      "[2000]\tvalid_0's binary_logloss: 0.442525\n",
      "[4000]\tvalid_0's binary_logloss: 0.446147\n",
      "[6000]\tvalid_0's binary_logloss: 0.449435\n",
      "[8000]\tvalid_0's binary_logloss: 0.453442\n",
      "[10000]\tvalid_0's binary_logloss: 0.457505\n",
      "[12000]\tvalid_0's binary_logloss: 0.462215\n",
      "[14000]\tvalid_0's binary_logloss: 0.467625\n",
      "[16000]\tvalid_0's binary_logloss: 0.473548\n",
      "[18000]\tvalid_0's binary_logloss: 0.480887\n",
      "[20000]\tvalid_0's binary_logloss: 0.488663\n",
      "9 0.00738916256158\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "def LGB_predict(train_x,train_y,):\n",
    "    \n",
    "    print(\"LGB test\")\n",
    "    clf = lightgbm.LGBMClassifier(\n",
    "        boosting_type='gbdt', num_leaves=31, reg_alpha=0.0, reg_lambda=1,\n",
    "        max_depth=-1, n_estimators=20000, objective='binary',\n",
    "        subsample=0.7, colsample_bytree=0.7, subsample_freq=1,\n",
    "        learning_rate=0.05, min_child_weight=50, random_state=2008, n_jobs=-1\n",
    "    )\n",
    "    n_split=10\n",
    "    cv_split = sklearn.model_selection.KFold(n_splits=n_split, random_state=15, shuffle=False)\n",
    "\n",
    "    #保存每个交叉验证在y_test集上的结果\n",
    "    #y_pred_test_cv=np.ones((test_x.shape[0],n_split))#\n",
    "    #y_pred_train_cv=np.ones((train_x.shape[0],))    \n",
    "    for i, (train_index,test_index) in enumerate(cv_split.split(train_x,train_y)):     \n",
    "        clf.fit(train_x[train_index],train_y[train_index],eval_set=[(train_x[test_index],train_y[test_index])], \\\n",
    "                eval_metric='binary', verbose=2000)\n",
    "        y_pred=clf.predict(train_x[test_index])         \n",
    "        #print(y_pred)\n",
    "        #print(train_y[test_index].values)\n",
    "        print(i,f1_score(train_y[test_index],y_pred))\n",
    "    return clf\n",
    "clf=LGB_predict(train_x,np.array(train_y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:1: DeprecationWarning: Call to deprecated `most_similar` (Method will be removed in 4.0.0, use self.wv.most_similar() instead).\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('借', 0.4608169496059418),\n",
       " ('我差', 0.44239649176597595),\n",
       " ('永', 0.43275049328804016),\n",
       " ('享用', 0.4084711968898773),\n",
       " ('剩', 0.39401108026504517),\n",
       " ('差', 0.38787755370140076),\n",
       " ('借点', 0.38490962982177734),\n",
       " ('借出', 0.3805862367153168),\n",
       " ('要换', 0.3681598901748657),\n",
       " ('刚借', 0.36452716588974)]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc2vec.most_similar('欠')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
