{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. \n",
    "    1.1 模型处理\n",
    "        1.2 获取数据\n",
    "        1.3 模型\n",
    "        1.4 多个模型\n",
    "        1.5 融合\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "F:\\app\\anaconda\\lib\\site-packages\\gensim\\utils.py:1197: UserWarning: detected Windows; aliasing chunkize to chunkize_serial\n",
      "  warnings.warn(\"detected Windows; aliasing chunkize to chunkize_serial\")\n"
     ]
    }
   ],
   "source": [
    "import jieba \n",
    "import gensim\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import jieba.analyse\n",
    "import lightgbm\n",
    "import sklearn\n",
    "import torch\n",
    "from torch import nn\n",
    "from sklearn.metrics import f1_score\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from batch_size import datasets\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from preprocess import pre_train\n",
    "import config as c\n",
    "word2vec_model=gensim.models.KeyedVectors.load_word2vec_format(c.word2vec_file)\n",
    "load_word=pre_train()\n",
    "data=load_word.load_word()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data(idx):\n",
    "    '''\n",
    "    就是把数据传入啊\n",
    "    '''\n",
    "    q1=np.zeros((len(idx),128))\n",
    "    q2=np.zeros((len(idx),128))    \n",
    "    for i,j in enumerate(idx):        \n",
    "        q1[i]=transform_word_vector(data['q1'][j-1])\n",
    "        q2[i]=transform_word_vector(data['q2'][j-1])        \n",
    "    target=np.array([data['target'][i-1] for i in idx])\n",
    "    return q1,q2,target \n",
    "\n",
    "def transform_word_vector(word_lists):\n",
    "    '''\n",
    "    分好词的句子的列表\n",
    "    '''\n",
    "    re=np.zeros((len(word_lists),128))\n",
    "    for i,word in enumerate(word_lists):\n",
    "        try:\n",
    "            re[i]=word2vec_model[word]\n",
    "        except:\n",
    "            pass \n",
    "    return re.mean(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset=datasets()\n",
    "datas=DataLoader(dataset,batch_size=40000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. lightgbm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {\n",
    "    'boosting_type': 'gbdt',\n",
    "    'objective': 'binary',\n",
    "    'metric': 'auc',\n",
    "    'num_leaves': 5,\n",
    "    'learning_rate': 0.10,\n",
    "    'feature_fraction': 0.7,\n",
    "    'bagging_fraction': 0.8,\n",
    "    'bagging_freq': 3,    \n",
    "    'reg_lambda':0.9,    \n",
    "    'subsample':0.8,\n",
    "    'subsample_freq':30,  \n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 50 rounds.\n",
      "[150]\ttraining's auc: 0.717622\n",
      "[300]\ttraining's auc: 0.775539\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[300]\ttraining's auc: 0.775539\n",
      "f1_scire 0 0.4149298597194389\n",
      "Training until validation scores don't improve for 50 rounds.\n",
      "[450]\ttraining's auc: 0.806446\n",
      "[600]\ttraining's auc: 0.836729\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[600]\ttraining's auc: 0.836729\n",
      "f1_scire 1 0.4557804269476019\n",
      "Training until validation scores don't improve for 50 rounds.\n",
      "[750]\ttraining's auc: 0.775617\n",
      "[900]\ttraining's auc: 0.838107\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[900]\ttraining's auc: 0.838107\n",
      "f1_scire 2 0.47715247715247716\n"
     ]
    }
   ],
   "source": [
    "for i,idx in enumerate(datas):\n",
    "    q1,q2,train_y=get_data(idx.numpy())\n",
    "    train_x=np.hstack([q1,q2])\n",
    "\n",
    "    lgb_train = lightgbm.Dataset(train_x, train_y,free_raw_data=True)    \n",
    "    if i==0:\n",
    "        model_name=None\n",
    "    else:\n",
    "        model_name=estimator\n",
    "    estimator = lightgbm.train(params,\n",
    "                    lgb_train,\n",
    "                    num_boost_round=300,\n",
    "                    valid_sets=lgb_train,\n",
    "                    init_model=model_name,\n",
    "                    keep_training_booster=False,\n",
    "                    early_stopping_rounds=50,\n",
    "                    verbose_eval=150,\n",
    "                    )\n",
    "    y=estimator.predict(train_x).reshape(-1,1)\n",
    "    y_pred=[int(i>0.16) for i in y]\n",
    "    print('f1_score',i,f1_score(train_y,y_pred))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 保存模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "estimator.save_model('../model/lightgbm_model')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* load 模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bst = lightgbm.Booster(model_file='../model/lightgbm_model')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 训练的结果导致需要一个阈值来保证最大化\n",
    "        如何求阈值？"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 将两列合并之后再训练\n",
    "   \n",
    "       1.1 lightgbm 简单\n",
    "       1.2 线性呢？\n",
    "       1.3 torch神经网络？"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 先训练，然后在合并"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
